<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimal Control Problems · RATiLQR.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="RATiLQR.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">RATiLQR.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting-started/">Getting Started</a></li><li class="is-active"><a class="tocitem" href>Optimal Control Problems</a><ul class="internal"><li><a class="tocitem" href="#Basics"><span>Basics</span></a></li><li><a class="tocitem" href="#Supported-Problem-Types"><span>Supported Problem Types</span></a></li><li><a class="tocitem" href="#Problem-Definition-APIs"><span>Problem Definition APIs</span></a></li></ul></li><li><a class="tocitem" href="../solvers/">Solver APIs</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Optimal Control Problems</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimal Control Problems</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/StanfordMSL/RATiLQR.jl/blob/master/docs/source/optimal-control.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimal-Control-Problems"><a class="docs-heading-anchor" href="#Optimal-Control-Problems">Optimal Control Problems</a><a id="Optimal-Control-Problems-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-Control-Problems" title="Permalink"></a></h1><h2 id="Basics"><a class="docs-heading-anchor" href="#Basics">Basics</a><a id="Basics-1"></a><a class="docs-heading-anchor-permalink" href="#Basics" title="Permalink"></a></h2><p>Suppose that we are given a discrete-time stochastic dynamics model of the form</p><p class="math-container">\[x_{k+1} = f(x_k, u_k, w_k),\]</p><p>where <span>$x_k \in \mathbb{R}^n$</span> is the state, <span>$u_k \in \mathbb{R}^m$</span> is the control input, and  <span>$w_k \in \mathbb{R}^r$</span> is the stochastic noise variable drawn from some probability distribution on <span>$\mathbb{R}^r$</span>.</p><p>Subject to the dynamics constraint, we are interested in minimizing an objective function <span>$J$</span> over  some finite horizon <span>$N$</span>:</p><p class="math-container">\[J(x_{0:N}, u_{0:N-1}) \triangleq \sum_{k=0}^{N - 1} c(k, x_k, u_k) + h(x_N),\]</p><p>where <span>$c(k, x_k, u_k) \geq 0$</span> is the stage cost at time <span>$k$</span> and <span>$h(x_N) \geq 0$</span> is the terminal cost.</p><p>Although not explicitly written above, the actual value of <span>$J$</span> is dependent on the history of stochastic  noise <span>$w_{0:N-1}$</span>. This means that the objective <span>$J$</span> itself is a random variable whose value cannot  be determined without actually observing the outcome. Therefore, Stochastic Opimal Control seeks to minimize a  statistic associated with the objective, such as the expectation <span>$\mathbb{E}[J]$</span>.</p><h2 id="Supported-Problem-Types"><a class="docs-heading-anchor" href="#Supported-Problem-Types">Supported Problem Types</a><a id="Supported-Problem-Types-1"></a><a class="docs-heading-anchor-permalink" href="#Supported-Problem-Types" title="Permalink"></a></h2><p>With RATiLQR.jl, you can formulate various types of stochastic optimal control problems with different objective  statistics and dynamics models.</p><h3 id=".-Standard-Problem-with-Gaussian-Noise"><a class="docs-heading-anchor" href="#.-Standard-Problem-with-Gaussian-Noise">1. Standard Problem with Gaussian Noise</a><a id=".-Standard-Problem-with-Gaussian-Noise-1"></a><a class="docs-heading-anchor-permalink" href="#.-Standard-Problem-with-Gaussian-Noise" title="Permalink"></a></h3><ul><li>Objective: <span>$\mathbb{E}[J]$</span></li><li>Dynamics: <span>$f(x_k, u_k, w_k) = f(x_k, u_k) + w_k, ~ w_k \sim \mathcal{N}(0, W_k)$</span></li><li>Definition: <a href="#RATiLQR.FiniteHorizonRiskSensitiveOptimalControlProblem"><code>FiniteHorizonRiskSensitiveOptimalControlProblem</code></a></li><li>Solvers: <a href="../solvers/#RATiLQR.ILEQGSolver"><code>ILEQGSolver</code></a></li></ul><h3 id=".-Standard-Problem-with-Arbitrary-Noise"><a class="docs-heading-anchor" href="#.-Standard-Problem-with-Arbitrary-Noise">2. Standard Problem with Arbitrary Noise</a><a id=".-Standard-Problem-with-Arbitrary-Noise-1"></a><a class="docs-heading-anchor-permalink" href="#.-Standard-Problem-with-Arbitrary-Noise" title="Permalink"></a></h3><ul><li>Objective: <span>$\mathbb{E}[J]$</span></li><li>Dynamics: <span>$f(x_k, u_k, w_k)$</span> where <span>$w_k$</span> has an arbitrary distribution.</li><li>Definition: <a href="#RATiLQR.FiniteHorizonGenerativeOptimalControlProblem"><code>FiniteHorizonGenerativeOptimalControlProblem</code></a></li><li>Solvers: <a href="../solvers/#RATiLQR.CrossEntropyDirectOptimizationSolver"><code>CrossEntropyDirectOptimizationSolver</code></a></li></ul><h3 id=".-Risk-Sensitive-Problem-with-Gaussian-Noise"><a class="docs-heading-anchor" href="#.-Risk-Sensitive-Problem-with-Gaussian-Noise">3. Risk-Sensitive Problem with Gaussian Noise</a><a id=".-Risk-Sensitive-Problem-with-Gaussian-Noise-1"></a><a class="docs-heading-anchor-permalink" href="#.-Risk-Sensitive-Problem-with-Gaussian-Noise" title="Permalink"></a></h3><ul><li>Objective: <span>$\frac{1}{\theta}\log\left(\mathbb{E}[\exp(\theta J)]\right)$</span> where <span>$\theta &gt; 0$</span> denotes the risk-sensitivity parameter and is user-specified.</li><li>Dynamics: <span>$f(x_k, u_k, w_k) = f(x_k, u_k) + w_k, ~ w_k \sim \mathcal{N}(0, W_k)$</span></li><li>Definition: <a href="#RATiLQR.FiniteHorizonRiskSensitiveOptimalControlProblem"><code>FiniteHorizonRiskSensitiveOptimalControlProblem</code></a></li><li>Solvers: <a href="../solvers/#RATiLQR.ILEQGSolver"><code>ILEQGSolver</code></a></li></ul><h3 id=".-Distributionally-Robust-Problem"><a class="docs-heading-anchor" href="#.-Distributionally-Robust-Problem">4. Distributionally-Robust Problem</a><a id=".-Distributionally-Robust-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#.-Distributionally-Robust-Problem" title="Permalink"></a></h3><ul><li>Objective: <span>$\max_{p \in \Xi} \mathbb{E}_p [J]$</span> where <span>$p$</span> denotes the true, potentially unknown  distribution over the noise variables <span>$w_{0:N-1}$</span> and <span>$\Xi$</span> is the ambiguity set that encodes how uncertain we are about the true distribution. Note that <span>$p$</span> may not be Gaussian. In our formulation, <span>$\Xi$</span> is defined by a KL divergence  bound between the true distribution <span>$p(w_{0:N-1})$</span> and the Gaussian model  <span>$q(w_{0:N-1}) \triangleq \prod_{k = 0}^{N - 1} \mathcal{N}(0, W_k)$</span> as follows:<p class="math-container">\[\Xi \triangleq \{p: \mathbb{D}_\mathrm{KL}(p \Vert q) \leq d\},\]</p>where <span>$d &gt; 0$</span> is a user-specified constant that defines an upper bound.</li><li>Dynamics: <span>$f(x_k, u_k, w_k) = f(x_k, u_k) + w_k$</span> where <span>$w_{0:N-1}$</span> can have an arbitrary distribution as long as it is within the ambiguity set defined by the Gaussian model.</li><li>Definition: <a href="#RATiLQR.FiniteHorizonRiskSensitiveOptimalControlProblem"><code>FiniteHorizonRiskSensitiveOptimalControlProblem</code></a></li><li>Solvers: <a href="../solvers/#RATiLQR.CrossEntropyBilevelOptimizationSolver"><code>CrossEntropyBilevelOptimizationSolver</code></a>, <a href="../solvers/#RATiLQR.NelderMeadBilevelOptimizationSolver"><code>NelderMeadBilevelOptimizationSolver</code></a></li></ul><h2 id="Problem-Definition-APIs"><a class="docs-heading-anchor" href="#Problem-Definition-APIs">Problem Definition APIs</a><a id="Problem-Definition-APIs-1"></a><a class="docs-heading-anchor-permalink" href="#Problem-Definition-APIs" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="RATiLQR.OptimalControlProblem" href="#RATiLQR.OptimalControlProblem"><code>RATiLQR.OptimalControlProblem</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">OptimalControlProblem</code></pre><p>Abstract base type for an Optimal Control Problem.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/StanfordMSL/RATiLQR.jl/blob/ecd3ffaf4374da4bbad33805d776c4556cd73cea/src/optimal_control_problems.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RATiLQR.FiniteHorizonRiskSensitiveOptimalControlProblem" href="#RATiLQR.FiniteHorizonRiskSensitiveOptimalControlProblem"><code>RATiLQR.FiniteHorizonRiskSensitiveOptimalControlProblem</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FiniteHorizonRiskSensitiveOptimalControlProblem(f, c, h, W, N) &lt;: OptimalControlProblem</code></pre><p>A finite horizon, stochastic optimal control problem where the dynamics function is subject to additive Gaussian noise w ~ N(0, W).</p><p><strong>Arguments</strong></p><ul><li><code>f(x, u, f_returns_jacobian=false)</code> – deterministic dynamics function<ul><li><code>x</code> is a state vector and <code>u</code> is a control input vector.</li><li>The third positional argument <code>f_returns_jacobian</code> determines whether the user computes and returns the Jacobians, and should default to <code>false</code>. If <code>true</code>, the return value must be augmented with matrices <code>A</code> and <code>B</code>, where <code>A = dx_next/dx</code> and <code>B = dx_next/du</code>. Otherwise the return value is the (noiseless) next state <code>x_next</code>.</li></ul></li><li><code>c(k, x, u)</code> – stage cost function<ul><li><code>k::Int &gt;= 0</code> is a time index where <code>k == 0</code> is the initial time.</li><li>We assume that <code>c</code> is non-negative.</li></ul></li><li><code>h(x)</code> – terminal cost function<ul><li>We assume that <code>h</code> is non-negative.</li></ul></li><li><code>W(k)</code> – covariance matrix function<ul><li>Returns a symmetric positive semidefinite matrix that represents the covariance matrix for additive Gaussian noise w ~ N(0, W).</li><li><code>k::Int &gt;= 0</code> is a time index where <code>k == 0</code> is the initial time.</li></ul></li><li><code>N::Int64</code> – final time index<ul><li>Note that <code>0</code> is the initial time index.</li></ul></li></ul><p><strong>Notes</strong></p><ul><li>Functions <code>f</code>, <code>c</code>, and <code>h</code> should be written generically enough to accept the state <code>x</code> and the input <code>u</code> of type <code>Vector{&lt;:Real}</code>. This is to ensure that ForwardDiff can compute Jacobians and Hessians for iLQG/iLEQG.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia">import LinearAlgebra;

function f(x, u, f_returns_jacobian=false)
    x_next = x + u; # 2D single integrator dynamics
    if f_returns_jacobian
        A = Matrix(1.0LinearAlgebra.I, 2, 2); # dx_next/dx
        B = Matrix(1.0LinearAlgebra.I, 2, 2); # dx_next/du
        return x_next, A, B;
    else
        return x_next;
    end
end

c(k, x, u) = k/2*x&#39;*x + k/2*u&#39;*u  # time-dependent quadratic stage cost
N = 10;
h(x) = N/2*x&#39;*x; # quadratic terminal cost
W(k) = Matrix(0.1LinearAlgebra.I, 2, 2);

problem = FiniteHorizonRiskSensitiveOptimalControlProblem(f, c, h, W, N);</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/StanfordMSL/RATiLQR.jl/blob/ecd3ffaf4374da4bbad33805d776c4556cd73cea/src/optimal_control_problems.jl#L15-L66">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RATiLQR.FiniteHorizonGenerativeOptimalControlProblem" href="#RATiLQR.FiniteHorizonGenerativeOptimalControlProblem"><code>RATiLQR.FiniteHorizonGenerativeOptimalControlProblem</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FiniteHorizonGenerativeOptimalControlProblem(f_stochastic, c, h, N) &lt;: OptimalControlProblem</code></pre><p>A finite horizon, stochastic optimal control problem where the dynamics function is stochastic and generative.</p><p><strong>Arguments</strong></p><ul><li><p><code>f_stochastic(x, u, rng, use_true_model=false)</code> – stochastic dynamics function</p><ul><li><code>x</code> is a state vector and <code>u</code> is a control input vector.</li><li>The third positional argument <code>rng</code> is a random seed.</li><li>The fourth positional argument <code>use_true_model</code> determines whether a solver has access to the true stochastic dynamics and defaults to <code>false</code>.</li><li>The return value is the (noisy) next state <code>x_next</code>.</li></ul></li><li><p><code>c(k, x, u)</code> – stage cost function</p><ul><li><code>k::Int &gt;= 0</code> is a time index where <code>k == 0</code> is the initial time.</li><li>We assume that <code>c</code> is non-negative.</li></ul></li><li><p><code>h(x)</code> – terminal cost function</p><ul><li>We assume that <code>h</code> is non-negative.</li></ul></li><li><p><code>N::Int64</code> – final time index</p><ul><li>Note that <code>0</code> is the initial time index.</li></ul></li></ul><p><strong>Example</strong></p><pre><code class="language-julia">import Distributions;
import LinearAlgebra;

function f_stochastic(x, u, rng, use_true_model=false)
    Σ_1 = Matrix(0.5LinearAlgebra.I, 2, 2);

    if use_true_model  # accurate GMM model
        Σ_2 = Matrix(1.0LinearAlgebra.I, 2, 2)
        d = Distributions.MixtureModel([Distributions.MvNormal(zeros(2), Σ_1),
                                        Distributions.MvNormal(ones(2), Σ_2)],
                                        [0.5, 0.5]);
    else  # inaccurate Gaussian model
        d = Distributions.MvNormal(zeros(2), Σ_1);
    end

    x_next = x + u + Distributions.rand(rng, d); # 2D single integrator dynamics
    return x_next;
end

c(k, x, u) = k/2*x&#39;*x + k/2*u&#39;*u  # time-dependent quadratic stage cost
N = 10;
h(x) = N/2*x&#39;*x; # quadratic terminal cost
W(k) = Matrix(0.1LinearAlgebra.I, 2, 2);

problem = FiniteHorizonGenerativeOptimalControlProblem(f_stochastic, c, h, N);</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/StanfordMSL/RATiLQR.jl/blob/ecd3ffaf4374da4bbad33805d776c4556cd73cea/src/optimal_control_problems.jl#L76-L125">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../getting-started/">« Getting Started</a><a class="docs-footer-nextpage" href="../solvers/">Solver APIs »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 7 January 2021 18:11">Thursday 7 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
